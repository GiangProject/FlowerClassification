# src/model_service.py

import torch
import torchvision.transforms as transforms
from PIL import Image
import torchvision.models as models
import json
import torch.nn.functional as F
import os
import sys
import wikipediaapi
from sumy.summarizers.lsa import LsaSummarizer 
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer 

# --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N T∆Ø∆†NG ƒê·ªêI ---
BASE_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'web', 'models')
CLASS_MAPPING_PATH = os.path.join(BASE_PATH, 'cat_to_name.json')
COLOR_MAP_PATH = os.path.join(BASE_PATH, 'flower_color_map_optimized.json') 
WIKI_CACHE_PATH = os.path.join(BASE_PATH, 'wiki_cache.json')

# --- ƒê∆Ø·ªúNG D·∫™N C·ª¶A C√ÅC M√î H√åNH ---
MODEL_PATHS = {
    'ViT': os.path.join(BASE_PATH, 'exp_vit.pth'), 
    'B1': os.path.join(BASE_PATH, 'exp4_b1_continued.pth') 
}

# --- H·∫∞NG S·ªê ---
INPUT_SIZE = 224
NUM_CLASSES = 102
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Kh·ªüi t·∫°o Wikipedia ---
WIKI_VI = wikipediaapi.Wikipedia('FlowerApp (example@example.com)', 'vi')
WIKI_EN = wikipediaapi.Wikipedia('FlowerApp (example@example.com)', 'en')

# B·ªï sung bi·∫øn to√†n c·ª•c: L∆∞u tr·∫°ng th√°i v√† ƒëi·ªÉm c·ªßa m√¥ h√¨nh
MODEL_HEALTH_AND_ACC = {} 
MODEL_CACHE = {}

# ... (Logic Wikipedia gi·ªØ nguy√™n) ...

def smart_summarize(text, sentence_count=2):
    try:
        parser = PlaintextParser.from_string(text, Tokenizer("vietnamese")) 
        summarizer = LsaSummarizer()
        summary_sentences = summarizer(parser.document, sentence_count)
        return " ".join(str(s) for s in summary_sentences)
    except Exception:
        return text[:500] + "..."

if os.path.exists(WIKI_CACHE_PATH):
    try:
        with open(WIKI_CACHE_PATH, 'r', encoding='utf-8') as f: WIKI_CACHE = json.load(f)
    except Exception: WIKI_CACHE = {}
else: WIKI_CACHE = {}

def get_wiki_summary_cached(flower_name):
    if flower_name in WIKI_CACHE: return WIKI_CACHE[flower_name]
    try:
        page_vi = WIKI_VI.page(flower_name)
        if page_vi.exists(): summary = smart_summarize(page_vi.summary)
        else:
            page_en = WIKI_EN.page(flower_name)
            summary = smart_summarize(page_en.summary) if page_en.exists() else "Kh√¥ng c√≥ th√¥ng tin m√¥ t·∫£."
    except Exception as e:
        print(f"[‚ö†Ô∏è] L·ªói Wikipedia: {e}", file=sys.stderr)
        summary = "Kh√¥ng th·ªÉ t·∫£i th√¥ng tin Wikipedia."
    WIKI_CACHE[flower_name] = summary
    try:
        with open(WIKI_CACHE_PATH, 'w', encoding='utf-8') as f:
            json.dump(WIKI_CACHE, f, ensure_ascii=False, indent=2)
    except Exception as e:
         print(f"[‚ö†Ô∏è] Kh√¥ng th·ªÉ ghi cache Wikipedia: {e}", file=sys.stderr)
    return summary

# ... (Logic build_model_b1, build_model_vit gi·ªØ nguy√™n) ...

def build_model_b1(num_classes=NUM_CLASSES):
    model = models.efficientnet_b1(weights=None) 
    num_ftrs = model.classifier[1].in_features
    model.classifier[1] = torch.nn.Linear(in_features=num_ftrs, out_features=num_classes)
    return model

def build_model_vit(num_classes=NUM_CLASSES):
    model = models.vit_b_16(weights=None) 
    num_ftrs = model.heads.head.in_features
    model.heads.head = torch.nn.Linear(in_features=num_ftrs, out_features=num_classes)
    return model

def load_model_and_classes():
    """T·∫£i t·∫•t c·∫£ m√¥ h√¨nh, t√™n l·ªõp v√† h√†m ti·ªÅn x·ª≠ l√Ω v√†o b·ªô nh·ªõ."""
    print("üîß ƒêang t·∫£i c√°c m√¥ h√¨nh AI...")

    # 1. T·∫£i ViT
    try:
        model_vit = build_model_vit(num_classes=NUM_CLASSES).to(DEVICE)
        model_vit.load_state_dict(torch.load(MODEL_PATHS['ViT'], map_location=DEVICE))
        model_vit.eval()
        MODEL_CACHE['ViT'] = model_vit
        MODEL_HEALTH_AND_ACC['ViT'] = {'status': 'OK', 'acc': 91.9} # ƒêi·ªÉm ƒë√£ bi·∫øt
        print(f"‚úÖ ƒê√£ t·∫£i ViT-B/16.")
    except Exception as e:
        MODEL_HEALTH_AND_ACC['ViT'] = {'status': 'ERROR', 'acc': 0.0}
        print(f"‚ùå L·ªói t·∫£i ViT: {e}")

    # 2. T·∫£i B1
    try:
        model_b1 = build_model_b1(num_classes=NUM_CLASSES).to(DEVICE)
        model_b1.load_state_dict(torch.load(MODEL_PATHS['B1'], map_location=DEVICE))
        model_b1.eval()
        MODEL_CACHE['B1'] = model_b1
        MODEL_HEALTH_AND_ACC['B1'] = {'status': 'OK', 'acc': 89.5} # ƒêi·ªÉm ƒë√£ bi·∫øt
        print(f"‚úÖ ƒê√£ t·∫£i EfficientNet-B1.")
    except Exception as e:
        MODEL_HEALTH_AND_ACC['B1'] = {'status': 'ERROR', 'acc': 0.0}
        print(f"‚ùå L·ªói t·∫£i B1: {e}")

    # 3. T·∫£i t√™n l·ªõp v√† ti·ªÅn x·ª≠ l√Ω (Gi·ªØ nguy√™n)
    with open(CLASS_MAPPING_PATH, 'r', encoding='utf-8') as f:
        cat_to_name = json.load(f)
    class_names = [cat_to_name[str(i)] for i in range(1, NUM_CLASSES + 1)] 

    IMAGENET_MEAN = [0.485, 0.456, 0.406]
    IMAGENET_STD = [0.229, 0.224, 0.225]
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(INPUT_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)
    ])

    return class_names, preprocess

# Kh·ªëi kh·ªüi ƒë·ªông Global Caching
try:
    CLASS_NAMES, PREPROCESS = load_model_and_classes() 
    with open(COLOR_MAP_PATH, 'r', encoding='utf-8') as f:
        COLOR_MAP = json.load(f)
    print("‚úÖ M√¥ h√¨nh v√† t√†i nguy√™n ƒë√£ s·∫µn s√†ng.")
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi ƒë·ªông ·ª©ng d·ª•ng: {e}", file=sys.stderr)
    CLASS_NAMES, PREPROCESS, COLOR_MAP = [], None, {}

# ... (H√†m d·ª± ƒëo√°n predict gi·ªØ nguy√™n) ...

def predict(image_path, model_choice='ViT', top_k=3):
    """D·ª± ƒëo√°n t·ªëc ƒë·ªô cao (ch·ªâ ch·∫°y suy lu·∫≠n c∆° b·∫£n)."""
    
    MODEL = MODEL_CACHE.get(model_choice)
    if MODEL is None:
        return [{ "label": f"L·ªói Model: {model_choice} kh√¥ng t·ªìn t·∫°i", "probability": "0.00%", "color": "ƒêen", "summary": "Kh√¥ng t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh." }]

    try:
        # 1. X·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o
        pil_img = Image.open(image_path).convert('RGB')
        input_tensor = PREPROCESS(pil_img).unsqueeze(0).to(DEVICE)

        # 2. Ch·∫°y d·ª± ƒëo√°n (Suy lu·∫≠n 1 l·∫ßn)
        with torch.no_grad():
            output = MODEL(input_tensor)
            probs = F.softmax(output, dim=1)

        # 3. L·∫•y Top-K
        top_probs, top_indices = torch.topk(probs, top_k)
        top_probs = top_probs.squeeze().cpu().numpy()
        top_indices = top_indices.squeeze().cpu().numpy()
        
        # 4. T·∫†O K·∫æT QU·∫¢
        results = []
        for i in range(len(top_indices)):
            label_name = CLASS_NAMES[top_indices[i]]
            probability = top_probs[i]
            
            color = COLOR_MAP.get(label_name, "Kh√¥ng r√µ")
            summary = get_wiki_summary_cached(label_name)

            item = {
                "label": label_name,
                "probability": f"{probability * 100:.2f}%",
                "color": color,
                "summary": summary
            }
            
            results.append(item)

        return results

    except Exception as e:
        print(f"L·ªói d·ª± ƒëo√°n: {e}", file=sys.stderr)
        return [{ "label": "L·ªói x·ª≠ l√Ω ·∫£nh", "probability": "0.00%", "color": "ƒêen", "summary": "Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh ƒë·∫ßu v√†o." }]